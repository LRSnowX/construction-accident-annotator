import random
from pathlib import Path

import pandas as pd

from hints import (
    extract_features_enhanced,
    format_hint_line,
    get_seed_load_summary,
    load_hint_model_enhanced,
    maybe_expand_features,
    predict_non_construction_proba_enhanced,
    remove_learned_features,
    rollback_token_stats,
    rollback_update,
    save_hint_model_enhanced,
    update_model_online_enhanced,
    update_token_stats,
)
from utils import (
    clear_screen,
    display_case,
    get_user_input,
    load_progress,
    save_progress,
)


def main():
    print("=" * 80)
    print("                     å»ºç­‘ä¸šäº‹æ•…æ¡ˆä¾‹æ ‡æ³¨ç³»ç»Ÿ")
    print("=" * 80)

    # è®¾ç½®æ–‡ä»¶è·¯å¾„
    output_dir = Path("data/annotated")
    output_dir.mkdir(parents=True, exist_ok=True)

    # å°è¯•è¯»å–ä¸Šæ¬¡ä½¿ç”¨çš„ç”¨æˆ·å
    last_user_file = output_dir / ".last_user"
    last_user = None
    if last_user_file.exists():
        try:
            with open(last_user_file, "r", encoding="utf-8") as f:
                last_user = f.read().strip()
        except Exception:
            pass

    # äº¤äº’å¼è¯¢é—®ç”¨æˆ·å
    print("\nğŸ“ è¯·è¾“å…¥æ‚¨çš„ç”¨æˆ·å/æ ‡æ³¨è€…IDï¼ˆç”¨äºåŒºåˆ†ä¸åŒæ ‡æ³¨è€…çš„æ–‡ä»¶ï¼‰")
    if last_user:
        print(f"   ä¸Šæ¬¡ä½¿ç”¨: {last_user}")
        annotator_id = input(f"   ç”¨æˆ·å (ç›´æ¥å›è½¦ä½¿ç”¨ '{last_user}'): ").strip()
        if not annotator_id:
            annotator_id = last_user
            print(f"   âœ“ ç»§ç»­ä½¿ç”¨: {annotator_id}")
        else:
            print(f"   âœ“ ç”¨æˆ·å: {annotator_id}")
    else:
        annotator_id = input("   ç”¨æˆ·å: ").strip()
        if not annotator_id:
            annotator_id = "default"
            print(f"   âš ï¸  æœªè¾“å…¥ç”¨æˆ·åï¼Œä½¿ç”¨é»˜è®¤å€¼: {annotator_id}")
        else:
            print(f"   âœ“ ç”¨æˆ·å: {annotator_id}")

    # ä¿å­˜ç”¨æˆ·åä¾›ä¸‹æ¬¡ä½¿ç”¨
    try:
        with open(last_user_file, "w", encoding="utf-8") as f:
            f.write(annotator_id)
    except Exception:
        pass

    # äº¤äº’å¼è¯¢é—®æ˜¯å¦ä½¿ç”¨éšæœºæ¨¡å¼
    print("\nğŸ² æ˜¯å¦å¯ç”¨éšæœºæ ‡æ³¨æ¨¡å¼ï¼Ÿï¼ˆå¤šäººåä½œæ—¶å»ºè®®å¯ç”¨ï¼Œé¿å…å†²çªï¼‰")
    random_choice = input("   è¯·é€‰æ‹© (y/n, é»˜è®¤n): ").strip().lower()
    random_mode = random_choice == "y"

    if random_mode:
        print("   âœ“ éšæœºæ¨¡å¼å·²å¯ç”¨")
    else:
        print("   âœ“ é¡ºåºæ¨¡å¼ï¼ˆæŒ‰åŸå§‹é¡ºåºæ ‡æ³¨ï¼‰")

    print("\n" + "=" * 80)

    # è®¾ç½®æ–‡ä»¶è·¯å¾„
    raw_dir = Path("data/raw")
    output_dir = Path("data/annotated")

    # ç¡®ä¿ç›®å½•å­˜åœ¨
    raw_dir.mkdir(parents=True, exist_ok=True)
    output_dir.mkdir(parents=True, exist_ok=True)

    # è‡ªåŠ¨æ£€æµ‹ data/raw ç›®å½•ä¸‹çš„ CSV æ–‡ä»¶
    csv_files = list(raw_dir.glob("*.csv"))

    if not csv_files:
        print(f"\nâ— é”™è¯¯: åœ¨ {raw_dir}/ ç›®å½•ä¸‹æœªæ‰¾åˆ°ä»»ä½•CSVæ–‡ä»¶")
        print(f"\nè¯·å°†åŸå§‹CSVæ–‡ä»¶æ”¾åœ¨ {raw_dir}/ ç›®å½•ä¸‹")
        print("\næŒ‰å›è½¦é”®é€€å‡º...")
        input()
        return
    elif len(csv_files) == 1:
        # åªæœ‰ä¸€ä¸ªCSVæ–‡ä»¶ï¼Œç›´æ¥ä½¿ç”¨
        input_file = csv_files[0]
        print(f"\nğŸ“„ æ£€æµ‹åˆ°æ•°æ®æ–‡ä»¶: {input_file.name}")
    else:
        # å¤šä¸ªCSVæ–‡ä»¶ï¼Œè®©ç”¨æˆ·é€‰æ‹©
        print(f"\nğŸ“‚ æ£€æµ‹åˆ° {len(csv_files)} ä¸ªCSVæ–‡ä»¶ï¼Œè¯·é€‰æ‹©è¦æ ‡æ³¨çš„æ–‡ä»¶ï¼š")
        print()
        for i, csv_file in enumerate(csv_files, 1):
            file_size = csv_file.stat().st_size / (1024 * 1024)  # MB
            print(f"  {i}. {csv_file.name} ({file_size:.1f} MB)")
        print()

        while True:
            try:
                choice = input("è¯·è¾“å…¥æ–‡ä»¶åºå·: ").strip()
                file_index = int(choice) - 1
                if 0 <= file_index < len(csv_files):
                    input_file = csv_files[file_index]
                    print(f"\nâœ… å·²é€‰æ‹©: {input_file.name}")
                    break
                else:
                    print(f"âš ï¸  è¯·è¾“å…¥ 1 åˆ° {len(csv_files)} ä¹‹é—´çš„æ•°å­—")
            except ValueError:
                print("âš ï¸  è¯·è¾“å…¥æœ‰æ•ˆçš„æ•°å­—")

    print("\n" + "=" * 80)

    # ä½¿ç”¨åŸºç¡€åç§°ï¼Œå¦‚æœæœ‰æ ‡æ³¨è€…IDåˆ™åŠ ä¸ŠID
    if annotator_id:
        base_output_name = f"accident_cases_annotated_{annotator_id}"
    else:
        base_output_name = "accident_cases_annotated"

    output_parquet = output_dir / f"{base_output_name}.parquet"
    output_csv = output_dir / f"{base_output_name}.csv"
    progress_file = output_dir / f"{base_output_name}_progress.txt"

    # ä¼˜å…ˆä» Parquet åŠ è½½ï¼Œå¦åˆ™ä» CSVï¼Œæœ€åä»åŸå§‹æ–‡ä»¶
    if output_parquet.exists():
        print(f"æ£€æµ‹åˆ°å¿«é€ŸåŠ è½½æ–‡ä»¶ï¼Œæ­£åœ¨ä» {output_parquet} ç»§ç»­...")
        df = pd.read_parquet(output_parquet)
        start_index = load_progress(str(output_dir / base_output_name))
        # ç¡®ä¿start_indexä¸è¶…è¿‡æ€»æ¡ˆä¾‹æ•°
        start_index = min(start_index, len(df) - 1) if len(df) > 0 else 0
    elif output_csv.exists():
        print(f"æ£€æµ‹åˆ°å·²æ ‡æ³¨çš„CSVæ–‡ä»¶ï¼Œæ­£åœ¨ä» {output_csv} ç»§ç»­...")
        df = pd.read_csv(output_csv, encoding="utf-8-sig")
        start_index = load_progress(str(output_dir / base_output_name))
        # ç¡®ä¿start_indexä¸è¶…è¿‡æ€»æ¡ˆä¾‹æ•°
        start_index = min(start_index, len(df) - 1) if len(df) > 0 else 0
    else:
        print(f"æœªæ‰¾åˆ°æ ‡æ³¨æ–‡ä»¶ï¼Œæ­£åœ¨ä»åŸå§‹æ–‡ä»¶ {input_file.name} å¼€å§‹...")
        try:
            df = pd.read_csv(input_file, encoding="utf-8-sig")

            # æ£€æŸ¥å¿…éœ€åˆ—
            if "full_text" not in df.columns:
                print("\nâ— é”™è¯¯: CSVæ–‡ä»¶ä¸­ç¼ºå°‘å¿…éœ€çš„ 'full_text' åˆ—")
                print("\nè¯·ç¡®ä¿åŸå§‹CSVæ–‡ä»¶åŒ…å« full_text åˆ—ï¼ˆæ¡ˆä¾‹æ–‡æœ¬ï¼‰")
                print("å…¶ä»–åˆ—ï¼ˆå¦‚ titleã€urlã€date ç­‰ï¼‰ä¸ºå¯é€‰ï¼Œç¨‹åºä¼šè‡ªåŠ¨è¯†åˆ«")
                print("\næŒ‰å›è½¦é”®é€€å‡º...")
                input()
                return

            start_index = 0
        except Exception as e:
            print(f"è¯»å–æ–‡ä»¶å¤±è´¥: {e}")
            print("\næŒ‰å›è½¦é”®é€€å‡º...")
            input()
            return

    total_cases = len(df)

    # å¦‚æœæ˜¯éšæœºæ¨¡å¼ï¼Œåˆ›å»ºéšæœºç´¢å¼•åºåˆ—
    if random_mode:
        print("\nğŸ“Š éšæœºæ ‡æ³¨æ¨¡å¼å·²å¯ç”¨")

        # ä¿å­˜/åŠ è½½ç´¢å¼•æ˜ å°„
        index_file = output_dir / f"{base_output_name}_random_indices.txt"
        if index_file.exists():
            # åŠ è½½å·²ä¿å­˜çš„éšæœºåºåˆ—
            with open(index_file, "r") as f:
                indices = list(map(int, f.read().strip().split(",")))
            # éªŒè¯ç´¢å¼•åˆ—è¡¨é•¿åº¦æ˜¯å¦åŒ¹é…
            if len(indices) != total_cases:
                print(
                    f"âš ï¸  è­¦å‘Š: éšæœºç´¢å¼•æ–‡ä»¶é•¿åº¦({len(indices)})ä¸å½“å‰æ•°æ®({total_cases})ä¸åŒ¹é…ï¼Œå°†é‡æ–°ç”Ÿæˆ"
                )
                indices = list(range(total_cases))
                random.shuffle(indices)
                with open(index_file, "w") as f:
                    f.write(",".join(map(str, indices)))
        else:
            # ç¬¬ä¸€æ¬¡è¿è¡Œï¼Œç”Ÿæˆæ–°çš„éšæœºåºåˆ—
            indices = list(range(total_cases))
            random.shuffle(indices)
            with open(index_file, "w") as f:
                f.write(",".join(map(str, indices)))
    else:
        indices = None

    # åˆå§‹åŒ–åˆ—
    if "is_construction" not in df.columns:
        df["is_construction"] = pd.NA

    # è®¡ç®—å®é™…å·²æ ‡æ³¨çš„æ•°é‡ï¼ˆä¸åŒ…æ‹¬è·³è¿‡çš„ï¼‰
    already_annotated = (
        (df["is_construction"].notna()) & (df["is_construction"] != -1)
    ).sum()
    total_unannotated = total_cases - already_annotated

    print(f"\nå…±æœ‰ {total_cases} ä¸ªæ¡ˆä¾‹éœ€è¦æ ‡æ³¨")
    if random_mode:
        print(f"å·²æ ‡æ³¨: {already_annotated} æ¡ï¼Œå‰©ä½™: {total_unannotated} æ¡")
        print(f"(éšæœºæ¨¡å¼: å°†ä»ç¬¬ {start_index + 1} ä¸ªéšæœºä½ç½®ç»§ç»­)")
    else:
        print(f"å·²æ ‡æ³¨: {already_annotated} æ¡ï¼Œå‰©ä½™: {total_unannotated} æ¡")
        print(f"å½“å‰å°†ä»ç¬¬ {start_index + 1} æ¡æ•°æ®å¼€å§‹æ ‡æ³¨\n")

    annotation_history = []
    update_history = []  # å­˜å‚¨æ¨¡å‹å¢é‡ç”¨äºæ’¤é”€
    current_index = start_index
    annotated_count = 0  # è®°å½•æœ¬æ¬¡ä¼šè¯å®é™…æ ‡æ³¨çš„æ•°é‡

    # åŠ è½½æ™ºèƒ½æç¤ºæ¨¡å‹
    base_output_path = str(output_dir / base_output_name)
    hint_model = load_hint_model_enhanced(base_output_path)
    # æ‰“å°å…³é”®è¯åŠ è½½æ‘˜è¦
    try:
        print(get_seed_load_summary())
    except Exception:
        pass

    print("=" * 80)
    print("å‡†å¤‡å¼€å§‹æ ‡æ³¨...")
    if random_mode:
        print("- æ ‡æ³¨æ¨¡å¼: éšæœºé¡ºåº")
        print(f"- å·²æ ‡æ³¨: {already_annotated} æ¡")
        print(f"- å‰©ä½™æ•°é‡: {total_unannotated} æ¡")
    else:
        print("- æ ‡æ³¨æ¨¡å¼: é¡ºåºæ ‡æ³¨")
        print(f"- å·²æ ‡æ³¨: {already_annotated} æ¡")
        print(f"- èµ·å§‹ä½ç½®: ç¬¬ {start_index + 1} æ¡æ•°æ®")
        print(f"- å‰©ä½™æ•°é‡: {total_unannotated} æ¡")
    print("=" * 80)
    print("\næŒ‰å›è½¦é”®å¼€å§‹...")
    input()

    try:
        while current_index < total_cases:
            # å¦‚æœæ˜¯éšæœºæ¨¡å¼ï¼Œä½¿ç”¨éšæœºç´¢å¼•
            actual_index = indices[current_index] if indices else current_index

            # æ£€æŸ¥æ˜¯å¦å·²æ ‡æ³¨ï¼ˆéç©ºä¸”ä¸ç­‰äº-1è¡¨ç¤ºå·²æ ‡æ³¨ï¼‰
            if (
                pd.notna(df.loc[actual_index, "is_construction"])
                and df.loc[actual_index, "is_construction"] != -1
            ):
                # å·²æ ‡æ³¨ï¼Œè‡ªåŠ¨è·³è¿‡
                current_index += 1
                continue

            row = df.iloc[actual_index]
            display_case(row, current_index, total_cases, random_mode)

            # æ™ºèƒ½æç¤ºï¼ˆéå»ºç­‘ä¸šæ¦‚ç‡ï¼‰
            try:
                feats = extract_features_enhanced(hint_model, row)
                prob, contrib = predict_non_construction_proba_enhanced(
                    hint_model, feats
                )
                print(format_hint_line(prob, contrib))
            except Exception:
                feats = None

            # æ˜¾ç¤ºæ˜¯å¦ä¹‹å‰è¢«è·³è¿‡
            if (
                pd.notna(df.loc[actual_index, "is_construction"])
                and df.loc[actual_index, "is_construction"] == -1
            ):
                print("\n[æ­¤æ¡ˆä¾‹ä¹‹å‰è¢«è·³è¿‡]")

            user_input = get_user_input()

            if user_input == "1":
                df.loc[actual_index, "is_construction"] = 1
                print("âœ“ å·²æ ‡æ³¨ä¸º: å»ºç­‘ä¸šæ¡ˆä¾‹")
                annotation_history.append(actual_index)
                # åœ¨çº¿æ›´æ–°ï¼ˆå»ºç­‘ä¸š=0 -> éå»ºç­‘ä¸šæ¦‚ç‡åº”é™ä½ï¼‰
                if feats is not None:
                    lr_delta = update_model_online_enhanced(
                        hint_model, row, feats, label_non_construction=0
                    )
                    tok_delta = update_token_stats(
                        hint_model, row, label_non_construction=0
                    )
                    new_feats = maybe_expand_features(hint_model)
                    update_history.append(
                        {"lr": lr_delta, "tok": tok_delta, "new": new_feats}
                    )
                else:
                    update_history.append(None)
                current_index += 1
                annotated_count += 1
            elif user_input == "0":
                df.loc[actual_index, "is_construction"] = 0
                annotation_history.append(actual_index)
                print("âœ“ å·²æ ‡æ³¨ä¸º: éå»ºç­‘ä¸šæ¡ˆä¾‹")
                # åœ¨çº¿æ›´æ–°ï¼ˆéå»ºç­‘ä¸š=1 -> éå»ºç­‘ä¸šæ¦‚ç‡åº”å‡é«˜ï¼‰
                if feats is not None:
                    lr_delta = update_model_online_enhanced(
                        hint_model, row, feats, label_non_construction=1
                    )
                    tok_delta = update_token_stats(
                        hint_model, row, label_non_construction=1
                    )
                    new_feats = maybe_expand_features(hint_model)
                    update_history.append(
                        {"lr": lr_delta, "tok": tok_delta, "new": new_feats}
                    )
                else:
                    update_history.append(None)
                current_index += 1
                annotated_count += 1
            elif user_input in ["s", "skip"]:
                df.loc[actual_index, "is_construction"] = -1
                annotation_history.append(actual_index)
                print("âŠ˜ å·²è·³è¿‡æ­¤æ¡ˆä¾‹")
                update_history.append(None)
                current_index += 1
                annotated_count += 1
            elif user_input in ["u", "undo"]:
                if annotation_history:
                    last_actual_index = annotation_history.pop()
                    # æ¸…ç†ç›¸å…³åˆ—
                    df.loc[last_actual_index, "is_construction"] = pd.NA
                    print("â†¶ å·²æ’¤é”€ä¸Šä¸€ä¸ªæ ‡æ³¨")
                    annotated_count = max(0, annotated_count - 1)

                    # æ’¤é”€ä¸Šä¸€æ¬¡æ¨¡å‹æ›´æ–°
                    if update_history:
                        last_delta = update_history.pop()
                        try:
                            if last_delta:
                                if isinstance(last_delta, dict) and "lr" in last_delta:
                                    rollback_update(
                                        hint_model, last_delta.get("lr", {})
                                    )
                                    rollback_token_stats(
                                        hint_model, last_delta.get("tok", {})
                                    )
                                    remove_learned_features(
                                        hint_model, last_delta.get("new", [])
                                    )
                                else:
                                    rollback_update(hint_model, last_delta)
                        except Exception:
                            pass

                    # åœ¨éšæœºæ¨¡å¼ä¸‹ï¼Œéœ€è¦æ‰¾åˆ°last_actual_indexåœ¨indicesä¸­çš„ä½ç½®
                    if indices:
                        try:
                            # æ‰¾åˆ°ä¸Šä¸€ä¸ªæ ‡æ³¨æ¡ˆä¾‹åœ¨éšæœºåºåˆ—ä¸­çš„ä½ç½®
                            last_position = indices.index(last_actual_index)
                            current_index = last_position
                        except ValueError:
                            # å¦‚æœæ‰¾ä¸åˆ°ï¼Œä¿æŒå½“å‰ä½ç½®ä¸å˜
                            pass
                    else:
                        # é¡ºåºæ¨¡å¼ä¸‹ï¼Œç›´æ¥å›é€€åˆ°è¯¥ç´¢å¼•
                        current_index = last_actual_index
                else:
                    print("âš  æ²¡æœ‰å¯ä»¥æ’¤é”€çš„æ ‡æ³¨")
            elif user_input in ["q", "quit"]:
                print("\næ­£åœ¨ä¿å­˜å¹¶é€€å‡º...")
                save_progress(df, str(output_dir / base_output_name), current_index)
                return

            # æ¯å®é™…æ ‡æ³¨10ä¸ªæ¡ˆä¾‹è‡ªåŠ¨ä¿å­˜ï¼ˆä¸åŒ…æ‹¬è‡ªåŠ¨è·³è¿‡çš„ï¼‰
            if annotated_count > 0 and annotated_count % 10 == 0:
                save_progress(df, str(output_dir / base_output_name), current_index)
                # åŒæ­¥ä¿å­˜æ¨¡å‹
                try:
                    save_hint_model_enhanced(base_output_path, hint_model)
                except Exception:
                    pass

        clear_screen()
        print("ğŸ‰ æ­å–œï¼æ‰€æœ‰æ¡ˆä¾‹æ ‡æ³¨å®Œæˆï¼")
        save_progress(df, str(output_dir / base_output_name), current_index)
        try:
            save_hint_model_enhanced(base_output_path, hint_model)
        except Exception:
            pass

        if progress_file.exists():
            progress_file.unlink()

    except (KeyboardInterrupt, Exception) as e:
        print(f"\n\næ“ä½œä¸­æ–­æˆ–å‘ç”Ÿé”™è¯¯: {e}")
        print("æ­£åœ¨ç´§æ€¥ä¿å­˜è¿›åº¦...")
        save_progress(df, str(output_dir / base_output_name), current_index)
        try:
            save_hint_model_enhanced(base_output_path, hint_model)
        except Exception:
            pass


if __name__ == "__main__":
    main()
